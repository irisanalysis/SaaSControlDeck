#!/bin/bash
# SaaS Control Deck å¤šç¯å¢ƒæ•°æ®åŒæ­¥è„šæœ¬
# Usage: ./environment-sync.sh [sync_type] [source_env] [target_env]

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/../.." && pwd)"

# é¢œè‰²è¾“å‡º
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# ç¯å¢ƒé…ç½®æ˜ å°„
declare -A ENV_DB_PORTS
ENV_DB_PORTS["development"]=5433
ENV_DB_PORTS["staging"]=5434
ENV_DB_PORTS["production"]=5432

declare -A ENV_DB_NAMES
ENV_DB_NAMES["development"]="saascontrol_dev"
ENV_DB_NAMES["staging"]="saascontrol_staging" 
ENV_DB_NAMES["production"]="saascontrol_prod"

# è·å–æ•°æ®åº“è¿æ¥ä¿¡æ¯
get_db_connection() {
    local env_name=$1
    local db_port=${ENV_DB_PORTS[$env_name]}
    local db_name=${ENV_DB_NAMES[$env_name]}
    
    echo "postgresql://saascontrol_user:saascontrol_pass@localhost:${db_port}/${db_name}"
}

# éªŒè¯ç¯å¢ƒæœ‰æ•ˆæ€§
validate_environment() {
    local env_name=$1
    
    if [[ ! " development staging production " =~ " $env_name " ]]; then
        log_error "æ— æ•ˆçš„ç¯å¢ƒåç§°: $env_name (æ”¯æŒ: development, staging, production)"
        return 1
    fi
    
    local db_port=${ENV_DB_PORTS[$env_name]}
    local db_name=${ENV_DB_NAMES[$env_name]}
    
    # æ£€æŸ¥æ•°æ®åº“è¿æ¥
    if ! docker exec "saascontrol-postgres-${env_name}" pg_isready -U saascontrol_user -d "$db_name" > /dev/null 2>&1; then
        log_error "${env_name} ç¯å¢ƒæ•°æ®åº“ä¸å¯ç”¨ (ç«¯å£: ${db_port})"
        return 1
    fi
    
    return 0
}

# æ•°æ®è„±æ•å¤„ç†
sanitize_data() {
    local sql_file=$1
    
    log_info "å¯¹æ•°æ®è¿›è¡Œè„±æ•å¤„ç†..."
    
    # åˆ›å»ºè„±æ•åçš„SQLæ–‡ä»¶
    local sanitized_file="${sql_file}.sanitized"
    
    # è„±æ•å¤„ç†è§„åˆ™
    sed -E '
        # é‚®ç®±è„±æ•
        s/[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}/test_user@example.com/g
        # æ‰‹æœºå·è„±æ•
        s/\b1[3-9]\d{9}\b/13800000000/g
        # èº«ä»½è¯å·è„±æ•
        s/\b[1-9]\d{5}(19|20)\d{2}(0[1-9]|1[0-2])(0[1-9]|[12]\d|3[01])\d{3}[\dXx]\b/110000000000000000/g
        # å¯†ç hashè„±æ• (ä¿æŒæ ¼å¼)
        s/\$2[aby]\$[0-9]{2}\$[./A-Za-z0-9]{53}/\$2b\$12\$testhashedpasswordfordevlopment12345/g
        # IPåœ°å€è„±æ•
        s/\b([0-9]{1,3}\.){3}[0-9]{1,3}\b/127.0.0.1/g
        # APIå¯†é’¥è„±æ•
        s/sk-[a-zA-Z0-9]{48}/sk-test1234567890abcdef1234567890abcdef12345678/g
    ' "$sql_file" > "$sanitized_file"
    
    echo "$sanitized_file"
}

# ç”Ÿäº§æ•°æ®åŒæ­¥åˆ°æš‚å­˜ç¯å¢ƒï¼ˆè„±æ•ï¼‰
sync_prod_to_staging() {
    log_info "å¼€å§‹ç”Ÿäº§ç¯å¢ƒåˆ°æš‚å­˜ç¯å¢ƒçš„æ•°æ®åŒæ­¥ï¼ˆè„±æ•ï¼‰..."
    
    # éªŒè¯ç¯å¢ƒ
    if ! validate_environment "production" || ! validate_environment "staging"; then
        return 1
    fi
    
    local timestamp=$(date +"%Y%m%d_%H%M%S")
    local backup_dir="${PROJECT_ROOT}/backups"
    local backup_file="${backup_dir}/prod_to_staging_${timestamp}.sql"
    local sanitized_file="${backup_file}.sanitized"
    
    mkdir -p "$backup_dir"
    
    # 1. å¤‡ä»½ç”Ÿäº§æ•°æ®
    log_info "å¯¼å‡ºç”Ÿäº§ç¯å¢ƒæ•°æ®..."
    docker exec "saascontrol-postgres-production" pg_dump \
        -U saascontrol_user \
        -d saascontrol_prod \
        --clean --if-exists \
        > "$backup_file"
    
    if [ ! -s "$backup_file" ]; then
        log_error "ç”Ÿäº§ç¯å¢ƒæ•°æ®å¯¼å‡ºå¤±è´¥"
        return 1
    fi
    
    log_success "ç”Ÿäº§ç¯å¢ƒæ•°æ®å¯¼å‡ºå®Œæˆ: $backup_file"
    
    # 2. æ•°æ®è„±æ•
    sanitized_file=$(sanitize_data "$backup_file")
    log_success "æ•°æ®è„±æ•å¤„ç†å®Œæˆ: $sanitized_file"
    
    # 3. å¯¼å…¥åˆ°æš‚å­˜ç¯å¢ƒ
    log_info "å¯¼å…¥æ•°æ®åˆ°æš‚å­˜ç¯å¢ƒ..."
    docker exec -i "saascontrol-postgres-staging" psql \
        -U saascontrol_user \
        -d saascontrol_staging \
        < "$sanitized_file"
    
    if [ $? -eq 0 ]; then
        log_success "æ•°æ®åŒæ­¥å®Œæˆ: ç”Ÿäº§ç¯å¢ƒ â†’ æš‚å­˜ç¯å¢ƒï¼ˆè„±æ•ï¼‰"
        
        # 4. éªŒè¯åŒæ­¥ç»“æœ
        local prod_count=$(docker exec "saascontrol-postgres-production" psql \
            -U saascontrol_user -d saascontrol_prod \
            -t -c "SELECT COUNT(*) FROM users;" | tr -d ' ')
        local staging_count=$(docker exec "saascontrol-postgres-staging" psql \
            -U saascontrol_user -d saascontrol_staging \
            -t -c "SELECT COUNT(*) FROM users;" | tr -d ' ')
        
        log_info "åŒæ­¥éªŒè¯: ç”Ÿäº§ç¯å¢ƒç”¨æˆ·æ•°=$prod_count, æš‚å­˜ç¯å¢ƒç”¨æˆ·æ•°=$staging_count"
        
        # 5. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        rm -f "$backup_file" "$sanitized_file"
        log_info "ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†"
    else
        log_error "æ•°æ®åŒæ­¥å¤±è´¥"
        return 1
    fi
}

# é‡ç½®å¼€å‘ç¯å¢ƒæ•°æ®
reset_dev_environment() {
    log_info "å¼€å§‹é‡ç½®å¼€å‘ç¯å¢ƒæ•°æ®..."
    
    if ! validate_environment "development"; then
        return 1
    fi
    
    local sample_data_file="${PROJECT_ROOT}/scripts/database/sample-data-development.sql"
    
    # æ£€æŸ¥æ ·ä¾‹æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if [ ! -f "$sample_data_file" ]; then
        log_warning "å¼€å‘ç¯å¢ƒæ ·ä¾‹æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºåŸºç¡€æ ·ä¾‹æ•°æ®..."
        create_dev_sample_data "$sample_data_file"
    fi
    
    # 1. æ¸…ç©ºå¼€å‘æ•°æ®åº“
    log_info "æ¸…ç©ºå¼€å‘ç¯å¢ƒæ•°æ®..."
    docker exec "saascontrol-postgres-development" psql \
        -U saascontrol_user -d saascontrol_dev \
        -c "TRUNCATE TABLE users, user_profiles, projects, datasets, analysis_tasks, analysis_results, api_logs RESTART IDENTITY CASCADE;"
    
    # 2. å¯¼å…¥æ ·ä¾‹æ•°æ®
    log_info "å¯¼å…¥å¼€å‘ç¯å¢ƒæ ·ä¾‹æ•°æ®..."
    docker exec -i "saascontrol-postgres-development" psql \
        -U saascontrol_user -d saascontrol_dev \
        < "$sample_data_file"
    
    if [ $? -eq 0 ]; then
        log_success "å¼€å‘ç¯å¢ƒæ•°æ®é‡ç½®å®Œæˆ"
        
        # éªŒè¯æ•°æ®
        local dev_user_count=$(docker exec "saascontrol-postgres-development" psql \
            -U saascontrol_user -d saascontrol_dev \
            -t -c "SELECT COUNT(*) FROM users;" | tr -d ' ')
        
        log_info "å¼€å‘ç¯å¢ƒç”¨æˆ·æ•°: $dev_user_count"
    else
        log_error "å¼€å‘ç¯å¢ƒæ•°æ®é‡ç½®å¤±è´¥"
        return 1
    fi
}

# åˆ›å»ºå¼€å‘ç¯å¢ƒæ ·ä¾‹æ•°æ®
create_dev_sample_data() {
    local sample_file=$1
    
    cat > "$sample_file" << 'EOF'
-- SaaS Control Deck å¼€å‘ç¯å¢ƒæ ·ä¾‹æ•°æ®
-- Generated for development testing

-- æ’å…¥æµ‹è¯•ç”¨æˆ·
INSERT INTO users (id, email, username, hashed_password, is_active, created_at, updated_at) VALUES
(1, 'dev@example.com', 'developer', '$2b$12$testhashedpasswordfordevlopment12345', true, NOW(), NOW()),
(2, 'test@example.com', 'tester', '$2b$12$testhashedpasswordfordevlopment12345', true, NOW(), NOW()),
(3, 'admin@example.com', 'admin', '$2b$12$testhashedpasswordfordevlopment12345', true, NOW(), NOW());

-- æ’å…¥ç”¨æˆ·æ¡£æ¡ˆ
INSERT INTO user_profiles (user_id, first_name, last_name, phone, created_at, updated_at) VALUES
(1, 'Dev', 'User', '13800000001', NOW(), NOW()),
(2, 'Test', 'User', '13800000002', NOW(), NOW()),
(3, 'Admin', 'User', '13800000003', NOW(), NOW());

-- æ’å…¥æµ‹è¯•é¡¹ç›®
INSERT INTO projects (id, name, description, owner_id, created_at, updated_at) VALUES
(1, 'Development Project', 'Sample project for development testing', 1, NOW(), NOW()),
(2, 'Test Project', 'Sample project for testing features', 2, NOW(), NOW()),
(3, 'Demo Project', 'Demo project for showcasing features', 3, NOW(), NOW());

-- æ’å…¥æµ‹è¯•æ•°æ®é›†
INSERT INTO datasets (id, name, file_path, file_size, project_id, uploaded_by, created_at) VALUES
(1, 'sample-data.csv', '/data/sample-data.csv', 1024, 1, 1, NOW()),
(2, 'test-dataset.json', '/data/test-dataset.json', 2048, 2, 2, NOW()),
(3, 'demo-analytics.xlsx', '/data/demo-analytics.xlsx', 4096, 3, 3, NOW());

-- æ’å…¥åˆ†æä»»åŠ¡æ ·ä¾‹
INSERT INTO analysis_tasks (id, name, task_type, status, project_id, created_by, created_at, updated_at) VALUES
(1, 'Data Quality Check', 'quality_analysis', 'completed', 1, 1, NOW(), NOW()),
(2, 'Trend Analysis', 'trend_analysis', 'processing', 2, 2, NOW(), NOW()),
(3, 'Predictive Modeling', 'ml_prediction', 'pending', 3, 3, NOW(), NOW());

-- æ’å…¥åˆ†æç»“æœæ ·ä¾‹
INSERT INTO analysis_results (id, task_id, result_data, created_at) VALUES
(1, 1, '{"data_quality_score": 0.95, "issues_found": 2, "recommendations": ["Remove duplicates", "Handle missing values"]}', NOW()),
(2, 2, '{"trend_direction": "upward", "confidence": 0.87, "forecast_data": [1, 2, 3, 4, 5]}', NOW());

-- é‡ç½®åºåˆ—
SELECT setval('users_id_seq', (SELECT MAX(id) FROM users));
SELECT setval('projects_id_seq', (SELECT MAX(id) FROM projects));
SELECT setval('datasets_id_seq', (SELECT MAX(id) FROM datasets));
SELECT setval('analysis_tasks_id_seq', (SELECT MAX(id) FROM analysis_tasks));
SELECT setval('analysis_results_id_seq', (SELECT MAX(id) FROM analysis_results));
EOF

    log_success "å¼€å‘ç¯å¢ƒæ ·ä¾‹æ•°æ®æ–‡ä»¶å·²åˆ›å»º: $sample_file"
}

# æ•°æ®åº“SchemaåŒæ­¥
sync_database_schema() {
    local source_env=$1
    local target_env=$2
    
    log_info "åŒæ­¥æ•°æ®åº“Schema: ${source_env} â†’ ${target_env}"
    
    if ! validate_environment "$source_env" || ! validate_environment "$target_env"; then
        return 1
    fi
    
    local timestamp=$(date +"%Y%m%d_%H%M%S")
    local schema_file="${PROJECT_ROOT}/backups/schema_${source_env}_${timestamp}.sql"
    
    mkdir -p "$(dirname "$schema_file")"
    
    # 1. å¯¼å‡ºæºç¯å¢ƒSchema
    log_info "å¯¼å‡º ${source_env} ç¯å¢ƒSchema..."
    docker exec "saascontrol-postgres-${source_env}" pg_dump \
        -U saascontrol_user \
        -d "${ENV_DB_NAMES[$source_env]}" \
        --schema-only \
        --clean --if-exists \
        > "$schema_file"
    
    # 2. åº”ç”¨åˆ°ç›®æ ‡ç¯å¢ƒ
    log_info "åº”ç”¨Schemaåˆ° ${target_env} ç¯å¢ƒ..."
    docker exec -i "saascontrol-postgres-${target_env}" psql \
        -U saascontrol_user \
        -d "${ENV_DB_NAMES[$target_env]}" \
        < "$schema_file"
    
    if [ $? -eq 0 ]; then
        log_success "SchemaåŒæ­¥å®Œæˆ: ${source_env} â†’ ${target_env}"
        rm -f "$schema_file"
    else
        log_error "SchemaåŒæ­¥å¤±è´¥"
        return 1
    fi
}

# æ˜¾ç¤ºç¯å¢ƒçŠ¶æ€
show_environment_status() {
    echo "==============================================="
    echo "SaaS Control Deck å¤šç¯å¢ƒæ•°æ®åº“çŠ¶æ€"
    echo "==============================================="
    
    for env in "production" "staging" "development"; do
        local db_port=${ENV_DB_PORTS[$env]}
        local db_name=${ENV_DB_NAMES[$env]}
        
        echo ""
        echo "ğŸ”§ $env ç¯å¢ƒ:"
        echo "   æ•°æ®åº“ç«¯å£: $db_port"
        echo "   æ•°æ®åº“åç§°: $db_name"
        
        # æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
        if docker exec "saascontrol-postgres-${env}" pg_isready -U saascontrol_user -d "$db_name" > /dev/null 2>&1; then
            echo "   çŠ¶æ€: âœ… è¿è¡Œä¸­"
            
            # è·å–æ•°æ®ç»Ÿè®¡
            local user_count=$(docker exec "saascontrol-postgres-${env}" psql \
                -U saascontrol_user -d "$db_name" \
                -t -c "SELECT COUNT(*) FROM users;" 2>/dev/null | tr -d ' ' || echo "N/A")
            local project_count=$(docker exec "saascontrol-postgres-${env}" psql \
                -U saascontrol_user -d "$db_name" \
                -t -c "SELECT COUNT(*) FROM projects;" 2>/dev/null | tr -d ' ' || echo "N/A")
            
            echo "   ç”¨æˆ·æ•°é‡: $user_count"
            echo "   é¡¹ç›®æ•°é‡: $project_count"
        else
            echo "   çŠ¶æ€: âŒ ä¸å¯ç”¨"
        fi
    done
    
    echo ""
    echo "==============================================="
}

# æ˜¾ç¤ºä½¿ç”¨å¸®åŠ©
show_usage() {
    echo "SaaS Control Deck å¤šç¯å¢ƒæ•°æ®åŒæ­¥è„šæœ¬"
    echo ""
    echo "ç”¨æ³•:"
    echo "  $0 [æ“ä½œç±»å‹] [å‚æ•°...]"
    echo ""
    echo "æ“ä½œç±»å‹:"
    echo "  prod-to-staging     - ç”Ÿäº§ç¯å¢ƒåŒæ­¥åˆ°æš‚å­˜ç¯å¢ƒï¼ˆè„±æ•ï¼‰"
    echo "  reset-dev          - é‡ç½®å¼€å‘ç¯å¢ƒæ•°æ®ï¼ˆæ ·ä¾‹æ•°æ®ï¼‰"
    echo "  sync-schema        - åŒæ­¥æ•°æ®åº“Schema"
    echo "  status             - æ˜¾ç¤ºæ‰€æœ‰ç¯å¢ƒçŠ¶æ€"
    echo ""
    echo "ç¤ºä¾‹:"
    echo "  $0 prod-to-staging              # ç”Ÿäº§æ•°æ®åŒæ­¥åˆ°æš‚å­˜ï¼ˆè„±æ•ï¼‰"
    echo "  $0 reset-dev                   # é‡ç½®å¼€å‘ç¯å¢ƒ"
    echo "  $0 sync-schema production staging  # åŒæ­¥Schema fromç”Ÿäº§ toæš‚å­˜"
    echo "  $0 status                      # æŸ¥çœ‹ç¯å¢ƒçŠ¶æ€"
    echo ""
}

# ä¸»ç¨‹åºå…¥å£
main() {
    local operation=${1:-""}
    
    case $operation in
        "prod-to-staging")
            sync_prod_to_staging
            ;;
        "reset-dev")
            reset_dev_environment
            ;;
        "sync-schema")
            local source_env=$2
            local target_env=$3
            if [ -z "$source_env" ] || [ -z "$target_env" ]; then
                log_error "SchemaåŒæ­¥éœ€è¦æŒ‡å®šæºç¯å¢ƒå’Œç›®æ ‡ç¯å¢ƒ"
                echo "ç”¨æ³•: $0 sync-schema [source_env] [target_env]"
                exit 1
            fi
            sync_database_schema "$source_env" "$target_env"
            ;;
        "status")
            show_environment_status
            ;;
        "")
            show_usage
            exit 1
            ;;
        *)
            log_error "æ— æ•ˆçš„æ“ä½œç±»å‹: $operation"
            show_usage
            exit 1
            ;;
    esac
}

# è„šæœ¬æ‰§è¡Œå…¥å£
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi