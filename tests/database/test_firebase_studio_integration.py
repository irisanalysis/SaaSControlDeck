"""
Firebase Studioé›†æˆæµ‹è¯•å¥—ä»¶

æµ‹è¯•Firebase Studioç¯å¢ƒä¸å¤–éƒ¨PostgreSQLæ•°æ®åº“çš„é›†æˆ
"""

import pytest
import asyncpg
import asyncio
import os
import time
from typing import Dict, Any, List
from datetime import datetime, timezone
import subprocess
import json


class TestFirebaseStudioIntegration:
    """Firebase Studioé›†æˆæµ‹è¯•ç±»"""

    @pytest.mark.firebase_studio
    @pytest.mark.asyncio
    async def test_external_database_connectivity(self, all_db_connections: Dict[str, asyncpg.Connection]):
        """æµ‹è¯•Firebase Studioç¯å¢ƒè¿æ¥å¤–éƒ¨PostgreSQLæ•°æ®åº“"""
        print("ğŸ”„ æµ‹è¯•Firebase Studioç¯å¢ƒæ•°æ®åº“è¿æ¥")
        
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        is_firebase_studio = os.getenv('FIREBASE_STUDIO_ENV', 'false').lower() == 'true'
        workspace_id = os.getenv('WORKSPACE_ID', 'unknown')
        
        print(f"   Firebase Studioç¯å¢ƒ: {is_firebase_studio}")
        print(f"   å·¥ä½œç©ºé—´ID: {workspace_id}")
        
        successful_connections = 0
        connection_details = []
        
        for env_name, connection in all_db_connections.items():
            if connection is None:
                connection_details.append({
                    'env': env_name,
                    'status': 'failed',
                    'error': 'Connection is None'
                })
                continue
            
            try:
                # æµ‹è¯•åŸºæœ¬è¿æ¥
                start_time = time.time()
                result = await connection.fetchval("SELECT 'Firebase Studio Connection Test'")
                end_time = time.time()
                
                # è·å–è¿æ¥ä¿¡æ¯
                connection_info = await connection.fetchrow(
                    """
                    SELECT 
                        current_database() as db_name,
                        current_user as user_name,
                        inet_server_addr() as server_ip,
                        inet_server_port() as server_port,
                        version() as pg_version
                    """
                )
                
                connection_details.append({
                    'env': env_name,
                    'status': 'success',
                    'response_time_ms': (end_time - start_time) * 1000,
                    'db_name': connection_info['db_name'],
                    'user': connection_info['user_name'],
                    'server_ip': str(connection_info['server_ip']) if connection_info['server_ip'] else 'localhost',
                    'server_port': connection_info['server_port'],
                    'pg_version': connection_info['pg_version'][:50] + '...' if len(connection_info['pg_version']) > 50 else connection_info['pg_version']
                })
                
                successful_connections += 1
                
            except Exception as e:
                connection_details.append({
                    'env': env_name,
                    'status': 'failed',
                    'error': str(e)[:100]
                })
        
        print(f"âœ… å¤–éƒ¨æ•°æ®åº“è¿æ¥æµ‹è¯•ç»“æœ:")
        print(f"   æˆåŠŸè¿æ¥: {successful_connections}/{len(all_db_connections)}")
        
        for detail in connection_details:
            if detail['status'] == 'success':
                print(f"   âœ… {detail['env']}: {detail['response_time_ms']:.2f}ms")
                print(f"      æ•°æ®åº“: {detail['db_name']} ({detail['server_ip']}:{detail['server_port']})")
            else:
                print(f"   âŒ {detail['env']}: {detail['error']}")
        
        # æ–­è¨€ï¼šè‡³å°‘åº”è¯¥æœ‰ä¸€ä¸ªæˆåŠŸçš„è¿æ¥
        assert successful_connections > 0, f"Firebase Studioç¯å¢ƒæ— æ³•è¿æ¥ä»»ä½•å¤–éƒ¨æ•°æ®åº“"

    @pytest.mark.firebase_studio
    @pytest.mark.asyncio
    async def test_environment_variables_access(self):
        """æµ‹è¯•Firebase Studioç¯å¢ƒå˜é‡è®¿é—®"""
        print("ğŸ”„ æµ‹è¯•ç¯å¢ƒå˜é‡è®¿é—®")
        
        # Firebase Studioç‰¹å®šçš„ç¯å¢ƒå˜é‡
        firebase_env_vars = [
            'FIREBASE_PROJECT_ID',
            'FIREBASE_STUDIO_ENV',
            'WORKSPACE_ID',
            'PROJECT_ROOT'
        ]
        
        # æ•°æ®åº“ç›¸å…³çš„ç¯å¢ƒå˜é‡
        database_env_vars = [
            'TEST_DB_ENVIRONMENT',
            'DB_HOST',
            'DB_PORT'
        ]
        
        env_status = {}
        
        print("   Firebase Studioç¯å¢ƒå˜é‡:")
        for var in firebase_env_vars:
            value = os.getenv(var)
            env_status[var] = value is not None
            if value:
                # å¯¹äºæ•æ„Ÿä¿¡æ¯ï¼Œåªæ˜¾ç¤ºå‰å‡ ä¸ªå­—ç¬¦
                display_value = value if len(value) <= 20 else value[:10] + '...'
                print(f"   âœ… {var}: {display_value}")
            else:
                print(f"   âš ï¸  {var}: æœªè®¾ç½®")
        
        print("   æ•°æ®åº“ç¯å¢ƒå˜é‡:")
        for var in database_env_vars:
            value = os.getenv(var)
            env_status[var] = value is not None
            if value:
                print(f"   âœ… {var}: {value}")
            else:
                print(f"   âš ï¸  {var}: æœªè®¾ç½®")
        
        # æ£€æŸ¥å…³é”®ç¯å¢ƒå˜é‡
        critical_vars = ['TEST_DB_ENVIRONMENT']
        missing_critical = [var for var in critical_vars if not env_status.get(var, False)]
        
        if missing_critical:
            print(f"   âš ï¸  ç¼ºå°‘å…³é”®ç¯å¢ƒå˜é‡: {missing_critical}")
        
        return env_status

    @pytest.mark.firebase_studio
    @pytest.mark.asyncio
    async def test_network_latency_to_database(self, db_connection: asyncpg.Connection):
        """æµ‹è¯•Firebase Studioåˆ°å¤–éƒ¨æ•°æ®åº“çš„ç½‘ç»œå»¶è¿Ÿ"""
        print("ğŸ”„ æµ‹è¯•ç½‘ç»œå»¶è¿Ÿ")
        
        # æ‰§è¡Œå¤šæ¬¡ç½‘ç»œå¾€è¿”æµ‹è¯•
        latency_tests = []
        
        for i in range(10):
            start_time = time.time()
            result = await db_connection.fetchval("SELECT $1", f"latency_test_{i}")
            end_time = time.time()
            
            latency_ms = (end_time - start_time) * 1000
            latency_tests.append(latency_ms)
            
            assert result == f"latency_test_{i}", f"ç½‘ç»œé€šä¿¡æ•°æ®ä¸ä¸€è‡´: {result}"
        
        # è®¡ç®—å»¶è¿Ÿç»Ÿè®¡
        avg_latency = sum(latency_tests) / len(latency_tests)
        min_latency = min(latency_tests)
        max_latency = max(latency_tests)
        
        print(f"âœ… ç½‘ç»œå»¶è¿Ÿæµ‹è¯•ç»“æœ:")
        print(f"   å¹³å‡å»¶è¿Ÿ: {avg_latency:.2f}ms")
        print(f"   æœ€å°å»¶è¿Ÿ: {min_latency:.2f}ms")
        print(f"   æœ€å¤§å»¶è¿Ÿ: {max_latency:.2f}ms")
        print(f"   å»¶è¿ŸæŠ–åŠ¨: {max_latency - min_latency:.2f}ms")
        
        # æ€§èƒ½æ–­è¨€ - Firebase Studioåˆ°äº‘æ•°æ®åº“çš„å»¶è¿Ÿåº”è¯¥åˆç†
        assert avg_latency < 500, f"ç½‘ç»œå»¶è¿Ÿè¿‡é«˜: {avg_latency:.2f}ms"
        assert max_latency < 1000, f"æœ€å¤§å»¶è¿Ÿè¿‡é«˜: {max_latency:.2f}ms"
        
        return {
            'avg_latency_ms': avg_latency,
            'min_latency_ms': min_latency,
            'max_latency_ms': max_latency
        }

    @pytest.mark.firebase_studio
    @pytest.mark.asyncio
    async def test_development_server_integration(self):
        """æµ‹è¯•å¼€å‘æœåŠ¡å™¨é›†æˆ"""
        print("ğŸ”„ æµ‹è¯•å¼€å‘æœåŠ¡å™¨é›†æˆ")
        
        # æ£€æŸ¥å¼€å‘æœåŠ¡å™¨ç›¸å…³çš„è¿›ç¨‹
        try:
            # æ£€æŸ¥ç«¯å£9000æ˜¯å¦è¢«å ç”¨ï¼ˆFirebase Studioé¢„è§ˆç«¯å£ï¼‰
            import socket
            
            def check_port(host, port):
                with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
                    sock.settimeout(1)
                    result = sock.connect_ex((host, port))
                    return result == 0
            
            port_9000_open = check_port('localhost', 9000)
            
            print(f"   ç«¯å£9000çŠ¶æ€: {'å¼€å¯' if port_9000_open else 'å…³é—­'}")
            
            # å¦‚æœç«¯å£å¼€å¯ï¼Œå°è¯•è¿›è¡ŒHTTPè¯·æ±‚
            if port_9000_open:
                import aiohttp
                try:
                    async with aiohttp.ClientSession() as session:
                        async with session.get('http://localhost:9000', timeout=5) as response:
                            status = response.status
                            print(f"   HTTPå“åº”çŠ¶æ€: {status}")
                            
                            if status == 200:
                                content_type = response.headers.get('content-type', '')
                                print(f"   å†…å®¹ç±»å‹: {content_type}")
                                return {'dev_server_running': True, 'status': status}
                            
                except Exception as e:
                    print(f"   HTTPè¯·æ±‚å¤±è´¥: {str(e)[:50]}")
            
            return {'dev_server_running': port_9000_open}
            
        except Exception as e:
            print(f"   å¼€å‘æœåŠ¡å™¨æ£€æµ‹å¤±è´¥: {e}")
            return {'dev_server_running': False, 'error': str(e)}

    @pytest.mark.firebase_studio
    @pytest.mark.asyncio
    async def test_file_system_access(self):
        """æµ‹è¯•æ–‡ä»¶ç³»ç»Ÿè®¿é—®æƒé™"""
        print("ğŸ”„ æµ‹è¯•æ–‡ä»¶ç³»ç»Ÿè®¿é—®")
        
        # æµ‹è¯•é¡¹ç›®æ ¹ç›®å½•è®¿é—®
        project_root = os.getenv('PROJECT_ROOT', '/home/user/studio')
        
        access_results = {}
        
        # æµ‹è¯•ç›®å½•è®¿é—®
        test_directories = [
            project_root,
            os.path.join(project_root, 'frontend'),
            os.path.join(project_root, 'backend'),
            os.path.join(project_root, 'tests'),
            '/tmp'
        ]
        
        for directory in test_directories:
            try:
                accessible = os.path.exists(directory) and os.access(directory, os.R_OK)
                if accessible:
                    # å°è¯•åˆ—å‡ºç›®å½•å†…å®¹
                    contents = os.listdir(directory)
                    access_results[directory] = {
                        'accessible': True,
                        'item_count': len(contents),
                        'items': contents[:5]  # å‰5ä¸ªé¡¹ç›®
                    }
                else:
                    access_results[directory] = {'accessible': False}
                    
            except Exception as e:
                access_results[directory] = {
                    'accessible': False,
                    'error': str(e)
                }
        
        print("   ç›®å½•è®¿é—®æµ‹è¯•:")
        for directory, result in access_results.items():
            if result.get('accessible', False):
                print(f"   âœ… {directory}: {result.get('item_count', 0)} ä¸ªé¡¹ç›®")
            else:
                error_msg = result.get('error', 'æ— æƒé™')
                print(f"   âŒ {directory}: {error_msg}")
        
        # æµ‹è¯•ä¸´æ—¶æ–‡ä»¶åˆ›å»º
        temp_file_test = False
        try:
            temp_file_path = '/tmp/firebase_studio_test.txt'
            with open(temp_file_path, 'w') as f:
                f.write('Firebase Studio integration test')
            
            # éªŒè¯æ–‡ä»¶å­˜åœ¨
            if os.path.exists(temp_file_path):
                temp_file_test = True
                os.remove(temp_file_path)  # æ¸…ç†
                
        except Exception as e:
            print(f"   ä¸´æ—¶æ–‡ä»¶åˆ›å»ºå¤±è´¥: {e}")
        
        print(f"   ä¸´æ—¶æ–‡ä»¶åˆ›å»º: {'æˆåŠŸ' if temp_file_test else 'å¤±è´¥'}")
        
        return {
            'directory_access': access_results,
            'temp_file_creation': temp_file_test
        }

    @pytest.mark.firebase_studio
    @pytest.mark.asyncio
    async def test_concurrent_database_operations_from_studio(self, db_pool: asyncpg.Pool):
        """æµ‹è¯•ä»Firebase Studioç¯å¢ƒè¿›è¡Œå¹¶å‘æ•°æ®åº“æ“ä½œ"""
        print("ğŸ”„ æµ‹è¯•Firebase Studioå¹¶å‘æ•°æ®åº“æ“ä½œ")
        
        # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
        async with db_pool.acquire() as connection:
            table_exists = await connection.fetchval(
                "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'users')"
            )
        
        if not table_exists:
            pytest.skip("usersè¡¨ä¸å­˜åœ¨")

        async def firebase_studio_db_worker(worker_id: int):
            """æ¨¡æ‹ŸFirebase Studioç¯å¢ƒçš„æ•°æ®åº“å·¥ä½œè´Ÿè½½"""
            operations = []
            
            try:
                async with db_pool.acquire() as connection:
                    # 1. æŸ¥è¯¢æ“ä½œ
                    start_time = time.time()
                    count = await connection.fetchval("SELECT COUNT(*) FROM users")
                    query_time = time.time() - start_time
                    operations.append({'type': 'count_query', 'time': query_time, 'success': True})
                    
                    # 2. äº‹åŠ¡æ“ä½œ
                    start_time = time.time()
                    async with connection.transaction():
                        user_id = await connection.fetchval(
                            """
                            INSERT INTO users (email, username, password_hash, is_active)
                            VALUES ($1, $2, $3, $4)
                            RETURNING id
                            """,
                            f'firebase_studio_{worker_id}@example.com',
                            f'firebase_studio_user_{worker_id}',
                            'firebase_hash', True
                        )
                        
                        if user_id:
                            await connection.execute(
                                "UPDATE users SET is_active = false WHERE id = $1",
                                user_id
                            )
                    
                    transaction_time = time.time() - start_time
                    operations.append({'type': 'transaction', 'time': transaction_time, 'success': True})
                    
                    # 3. å¤æ‚æŸ¥è¯¢æ“ä½œ
                    start_time = time.time()
                    results = await connection.fetch(
                        """
                        SELECT is_active, COUNT(*) as count 
                        FROM users 
                        WHERE email LIKE $1
                        GROUP BY is_active
                        """,
                        '%firebase_studio%'
                    )
                    complex_query_time = time.time() - start_time
                    operations.append({'type': 'complex_query', 'time': complex_query_time, 'success': True})
                    
                return {
                    'worker_id': worker_id,
                    'operations': operations,
                    'total_success': True
                }
                
            except Exception as e:
                return {
                    'worker_id': worker_id,
                    'operations': operations,
                    'total_success': False,
                    'error': str(e)
                }

        # å¯åŠ¨å¤šä¸ªå¹¶å‘å·¥ä½œè¿›ç¨‹
        worker_count = 6
        start_time = time.time()
        
        tasks = []
        for worker_id in range(worker_count):
            task = asyncio.create_task(firebase_studio_db_worker(worker_id))
            tasks.append(task)
        
        results = await asyncio.gather(*tasks)
        end_time = time.time()
        total_time = end_time - start_time
        
        # åˆ†æç»“æœ
        successful_workers = sum(1 for r in results if r.get('total_success', False))
        
        operation_stats = {
            'count_query': [],
            'transaction': [],
            'complex_query': []
        }
        
        for result in results:
            if result.get('total_success', False):
                for op in result.get('operations', []):
                    if op['success'] and op['type'] in operation_stats:
                        operation_stats[op['type']].append(op['time'])
        
        print(f"âœ… Firebase Studioå¹¶å‘æ•°æ®åº“æ“ä½œç»“æœ:")
        print(f"   å·¥ä½œè¿›ç¨‹: {successful_workers}/{worker_count}")
        print(f"   æ€»è€—æ—¶: {total_time:.3f}ç§’")
        
        for op_type, times in operation_stats.items():
            if times:
                avg_time = sum(times) / len(times)
                print(f"   {op_type} å¹³å‡æ—¶é—´: {avg_time:.4f}ç§’ ({len(times)} æ¬¡æ“ä½œ)")
        
        # æ¸…ç†æµ‹è¯•æ•°æ®
        async with db_pool.acquire() as connection:
            await connection.execute("DELETE FROM users WHERE email LIKE 'firebase_studio_%'")
        
        # æ–­è¨€
        assert successful_workers >= worker_count * 0.8, \
            f"Firebase Studioå¹¶å‘æ“ä½œæˆåŠŸç‡è¿‡ä½: {successful_workers}/{worker_count}"

    @pytest.mark.firebase_studio
    @pytest.mark.asyncio
    async def test_external_api_access(self):
        """æµ‹è¯•å¤–éƒ¨APIè®¿é—®èƒ½åŠ›"""
        print("ğŸ”„ æµ‹è¯•å¤–éƒ¨APIè®¿é—®")
        
        # æµ‹è¯•å¯¹å¤–ç½‘çš„è®¿é—®
        api_tests = [
            {
                'name': 'Google DNS',
                'url': 'https://dns.google/resolve?name=example.com&type=A',
                'timeout': 10
            },
            {
                'name': 'HTTPBin Echo',
                'url': 'https://httpbin.org/json',
                'timeout': 10
            }
        ]
        
        api_results = []
        
        try:
            import aiohttp
            
            async with aiohttp.ClientSession() as session:
                for test in api_tests:
                    try:
                        start_time = time.time()
                        async with session.get(test['url'], timeout=test['timeout']) as response:
                            end_time = time.time()
                            response_time = end_time - start_time
                            
                            api_results.append({
                                'name': test['name'],
                                'success': True,
                                'status': response.status,
                                'response_time': response_time
                            })
                            
                    except Exception as e:
                        api_results.append({
                            'name': test['name'],
                            'success': False,
                            'error': str(e)[:100]
                        })
            
            print("   å¤–éƒ¨APIè®¿é—®æµ‹è¯•:")
            successful_apis = 0
            for result in api_results:
                if result['success']:
                    successful_apis += 1
                    print(f"   âœ… {result['name']}: {result['status']} ({result['response_time']:.3f}s)")
                else:
                    print(f"   âŒ {result['name']}: {result['error']}")
            
            return {
                'successful_apis': successful_apis,
                'total_apis': len(api_tests),
                'results': api_results
            }
            
        except ImportError:
            print("   âš ï¸  aiohttpä¸å¯ç”¨ï¼Œè·³è¿‡å¤–éƒ¨APIæµ‹è¯•")
            return {'successful_apis': 0, 'total_apis': 0, 'error': 'aiohttp_unavailable'}

    @pytest.mark.firebase_studio
    @pytest.mark.asyncio
    async def test_memory_and_resource_usage(self):
        """æµ‹è¯•å†…å­˜å’Œèµ„æºä½¿ç”¨æƒ…å†µ"""
        print("ğŸ”„ æµ‹è¯•èµ„æºä½¿ç”¨æƒ…å†µ")
        
        try:
            import psutil
            
            # è·å–å½“å‰è¿›ç¨‹ä¿¡æ¯
            process = psutil.Process()
            
            # å†…å­˜ä½¿ç”¨
            memory_info = process.memory_info()
            memory_percent = process.memory_percent()
            
            # CPUä½¿ç”¨ï¼ˆéœ€è¦çŸ­æš‚ç­‰å¾…æ¥è®¡ç®—ï¼‰
            cpu_percent = process.cpu_percent(interval=1)
            
            # æ–‡ä»¶æè¿°ç¬¦
            try:
                num_fds = process.num_fds() if hasattr(process, 'num_fds') else 'N/A'
            except:
                num_fds = 'N/A'
            
            # çº¿ç¨‹æ•°
            num_threads = process.num_threads()
            
            print(f"   èµ„æºä½¿ç”¨æƒ…å†µ:")
            print(f"   å†…å­˜ä½¿ç”¨: {memory_info.rss / 1024 / 1024:.2f} MB ({memory_percent:.1f}%)")
            print(f"   CPUä½¿ç”¨: {cpu_percent:.1f}%")
            print(f"   çº¿ç¨‹æ•°: {num_threads}")
            print(f"   æ–‡ä»¶æè¿°ç¬¦: {num_fds}")
            
            # ç³»ç»Ÿèµ„æº
            system_memory = psutil.virtual_memory()
            system_cpu = psutil.cpu_percent(interval=1)
            
            print(f"   ç³»ç»Ÿèµ„æº:")
            print(f"   ç³»ç»Ÿå†…å­˜: {system_memory.percent:.1f}% å·²ä½¿ç”¨")
            print(f"   ç³»ç»ŸCPU: {system_cpu:.1f}%")
            
            return {
                'process_memory_mb': memory_info.rss / 1024 / 1024,
                'process_memory_percent': memory_percent,
                'process_cpu_percent': cpu_percent,
                'process_threads': num_threads,
                'system_memory_percent': system_memory.percent,
                'system_cpu_percent': system_cpu
            }
            
        except ImportError:
            print("   âš ï¸  psutilä¸å¯ç”¨ï¼Œæ— æ³•è·å–èµ„æºä¿¡æ¯")
            return {'error': 'psutil_unavailable'}
        except Exception as e:
            print(f"   âš ï¸  èµ„æºç›‘æ§å¤±è´¥: {e}")
            return {'error': str(e)}

    @pytest.mark.firebase_studio
    @pytest.mark.asyncio
    async def test_database_connection_persistence(self, db_pool: asyncpg.Pool):
        """æµ‹è¯•æ•°æ®åº“è¿æ¥æŒä¹…æ€§ï¼ˆFirebase Studioç¯å¢ƒç‰¹æœ‰çš„ç½‘ç»œæ¡ä»¶ï¼‰"""
        print("ğŸ”„ æµ‹è¯•æ•°æ®åº“è¿æ¥æŒä¹…æ€§")
        
        # æ¨¡æ‹Ÿé•¿æ—¶é—´è¿è¡Œçš„åº”ç”¨åœºæ™¯
        persistence_tests = []
        
        for i in range(5):
            try:
                async with db_pool.acquire() as connection:
                    # æ‰§è¡ŒæŸ¥è¯¢
                    start_time = time.time()
                    result = await connection.fetchval("SELECT CURRENT_TIMESTAMP")
                    query_time = time.time() - start_time
                    
                    # ç­‰å¾…ä¸€æ®µæ—¶é—´æ¨¡æ‹Ÿè¿æ¥ç©ºé—²
                    await asyncio.sleep(2)
                    
                    # å†æ¬¡æŸ¥è¯¢éªŒè¯è¿æ¥ä»ç„¶æœ‰æ•ˆ
                    start_time = time.time()
                    result2 = await connection.fetchval("SELECT 'connection_alive'")
                    query_time2 = time.time() - start_time
                    
                    persistence_tests.append({
                        'round': i + 1,
                        'success': True,
                        'first_query_time': query_time,
                        'second_query_time': query_time2,
                        'timestamp': result
                    })
                    
            except Exception as e:
                persistence_tests.append({
                    'round': i + 1,
                    'success': False,
                    'error': str(e)
                })
        
        # åˆ†æç»“æœ
        successful_rounds = sum(1 for t in persistence_tests if t.get('success', False))
        
        print(f"âœ… è¿æ¥æŒä¹…æ€§æµ‹è¯•ç»“æœ:")
        print(f"   æˆåŠŸè½®æ¬¡: {successful_rounds}/5")
        
        total_query_time = 0
        query_count = 0
        
        for test in persistence_tests:
            if test.get('success', False):
                round_num = test['round']
                q1_time = test['first_query_time'] * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
                q2_time = test['second_query_time'] * 1000
                
                print(f"   è½®æ¬¡{round_num}: æŸ¥è¯¢1={q1_time:.2f}ms, æŸ¥è¯¢2={q2_time:.2f}ms")
                
                total_query_time += q1_time + q2_time
                query_count += 2
            else:
                print(f"   è½®æ¬¡{test['round']}: å¤±è´¥ - {test.get('error', 'Unknown')[:50]}")
        
        if query_count > 0:
            avg_query_time = total_query_time / query_count
            print(f"   å¹³å‡æŸ¥è¯¢æ—¶é—´: {avg_query_time:.2f}ms")
        
        # æ–­è¨€ï¼šè¿æ¥åº”è¯¥ä¿æŒç¨³å®š
        assert successful_rounds >= 4, \
            f"è¿æ¥æŒä¹…æ€§ä¸è¶³: ä»… {successful_rounds}/5 è½®æˆåŠŸ"

    @pytest.mark.firebase_studio
    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_full_stack_integration(self, db_connection: asyncpg.Connection):
        """æµ‹è¯•å®Œæ•´æŠ€æœ¯æ ˆé›†æˆï¼ˆFirebase Studio + å¤–éƒ¨PostgreSQL + åº”ç”¨é€»è¾‘ï¼‰"""
        print("ğŸ”„ æµ‹è¯•å®Œæ•´æŠ€æœ¯æ ˆé›†æˆ")
        
        # æ¨¡æ‹Ÿå®Œæ•´çš„åº”ç”¨å·¥ä½œæµ
        integration_results = {}
        
        # 1. æ•°æ®åº“æ“ä½œæµ‹è¯•
        try:
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            tables_exist = await db_connection.fetchval(
                """
                SELECT COUNT(*) FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name IN ('users', 'projects')
                """
            )
            
            integration_results['database_schema'] = {
                'tables_found': tables_exist,
                'success': tables_exist > 0
            }
            
            if tables_exist > 0:
                # æ‰§è¡ŒCRUDæ“ä½œ
                # CREATE
                user_id = await db_connection.fetchval(
                    """
                    INSERT INTO users (email, username, password_hash, is_active)
                    VALUES ($1, $2, $3, $4)
                    RETURNING id
                    """,
                    'integration_test@firebase.studio', 'integration_user', 'test_hash', True
                )
                
                # READ
                user_data = await db_connection.fetchrow(
                    "SELECT * FROM users WHERE id = $1", user_id
                )
                
                # UPDATE
                await db_connection.execute(
                    "UPDATE users SET is_active = false WHERE id = $1", user_id
                )
                
                # éªŒè¯æ›´æ–°
                updated_status = await db_connection.fetchval(
                    "SELECT is_active FROM users WHERE id = $1", user_id
                )
                
                integration_results['crud_operations'] = {
                    'create_success': user_id is not None,
                    'read_success': user_data is not None,
                    'update_success': updated_status == False,
                    'success': all([user_id is not None, user_data is not None, updated_status == False])
                }
                
                # æ¸…ç†
                await db_connection.execute("DELETE FROM users WHERE id = $1", user_id)
            
        except Exception as e:
            integration_results['database_operations'] = {
                'success': False,
                'error': str(e)
            }
        
        # 2. å¹¶å‘æ“ä½œæµ‹è¯•
        try:
            concurrent_start = time.time()
            
            async def concurrent_query(query_id):
                return await db_connection.fetchval("SELECT $1", f"concurrent_test_{query_id}")
            
            # æ‰§è¡Œå¹¶å‘æŸ¥è¯¢
            tasks = [asyncio.create_task(concurrent_query(i)) for i in range(5)]
            concurrent_results = await asyncio.gather(*tasks)
            
            concurrent_end = time.time()
            concurrent_time = concurrent_end - concurrent_start
            
            integration_results['concurrency'] = {
                'success': len(concurrent_results) == 5,
                'execution_time': concurrent_time,
                'all_results_correct': all(f"concurrent_test_{i}" in str(concurrent_results[i]) for i in range(5))
            }
            
        except Exception as e:
            integration_results['concurrency'] = {
                'success': False,
                'error': str(e)
            }
        
        # 3. æ€§èƒ½åŸºå‡†æµ‹è¯•
        try:
            performance_queries = [
                "SELECT 1",
                "SELECT COUNT(*) FROM information_schema.tables",
                "SELECT CURRENT_TIMESTAMP",
                "SELECT version()",
                "SELECT pg_database_size(current_database())"
            ]
            
            query_times = []
            for query in performance_queries:
                start_time = time.time()
                await db_connection.fetchval(query)
                end_time = time.time()
                query_times.append((end_time - start_time) * 1000)  # ms
            
            avg_query_time = sum(query_times) / len(query_times)
            max_query_time = max(query_times)
            
            integration_results['performance'] = {
                'success': avg_query_time < 100,  # å¹³å‡æŸ¥è¯¢æ—¶é—´åº”å°äº100ms
                'avg_query_time_ms': avg_query_time,
                'max_query_time_ms': max_query_time,
                'total_queries': len(performance_queries)
            }
            
        except Exception as e:
            integration_results['performance'] = {
                'success': False,
                'error': str(e)
            }
        
        # æ±‡æ€»ç»“æœ
        total_tests = len(integration_results)
        successful_tests = sum(1 for result in integration_results.values() 
                             if isinstance(result, dict) and result.get('success', False))
        
        print(f"âœ… å®Œæ•´æŠ€æœ¯æ ˆé›†æˆæµ‹è¯•ç»“æœ:")
        print(f"   æˆåŠŸæµ‹è¯•: {successful_tests}/{total_tests}")
        
        for test_name, result in integration_results.items():
            if isinstance(result, dict):
                if result.get('success', False):
                    print(f"   âœ… {test_name}: é€šè¿‡")
                else:
                    error_msg = result.get('error', 'æœªçŸ¥é”™è¯¯')
                    print(f"   âŒ {test_name}: å¤±è´¥ - {error_msg[:50]}")
        
        # æœ€ç»ˆæ–­è¨€
        success_rate = successful_tests / total_tests
        assert success_rate >= 0.8, \
            f"å®Œæ•´æŠ€æœ¯æ ˆé›†æˆæˆåŠŸç‡è¿‡ä½: {success_rate:.1%}"
        
        return integration_results