"""
æ•°æ®åº“å¹¶å‘æ“ä½œæµ‹è¯•å¥—ä»¶

æµ‹è¯•å¤šç”¨æˆ·å¹¶å‘è®¿é—®ã€äº‹åŠ¡éš”ç¦»å’Œé”æœºåˆ¶
"""

import pytest
import asyncpg
import asyncio
import time
import random
from typing import Dict, Any, List
from datetime import datetime, timezone


class TestConcurrentOperations:
    """å¹¶å‘æ“ä½œæµ‹è¯•ç±»"""

    @pytest.mark.performance
    @pytest.mark.asyncio
    async def test_concurrent_connections(self, db_config: Dict[str, Any]):
        """æµ‹è¯•å¹¶å‘è¿æ¥å¤„ç†"""
        connection_string = f"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['db_name']}"
        
        async def create_connection_and_query(connection_id: int):
            """åˆ›å»ºè¿æ¥å¹¶æ‰§è¡ŒæŸ¥è¯¢"""
            try:
                connection = await asyncpg.connect(connection_string)
                
                # æ‰§è¡Œç®€å•æŸ¥è¯¢
                result = await connection.fetchval("SELECT $1 as connection_id", connection_id)
                
                # æ¨¡æ‹Ÿä¸€äº›å·¥ä½œè´Ÿè½½
                await asyncio.sleep(0.1)
                
                # æ‰§è¡Œå¦ä¸€ä¸ªæŸ¥è¯¢
                timestamp = await connection.fetchval("SELECT CURRENT_TIMESTAMP")
                
                await connection.close()
                return {
                    'connection_id': connection_id,
                    'result': result,
                    'timestamp': timestamp,
                    'success': True
                }
            except Exception as e:
                return {
                    'connection_id': connection_id,
                    'error': str(e),
                    'success': False
                }

        # æµ‹è¯•ä¸åŒå¹¶å‘çº§åˆ«
        concurrency_levels = [5, 10, 20]
        
        for concurrent_count in concurrency_levels:
            print(f"ğŸ”„ æµ‹è¯•å¹¶å‘è¿æ¥æ•°: {concurrent_count}")
            
            start_time = time.time()
            
            # åˆ›å»ºå¹¶å‘ä»»åŠ¡
            tasks = []
            for i in range(concurrent_count):
                task = asyncio.create_task(create_connection_and_query(i))
                tasks.append(task)
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            end_time = time.time()
            total_time = end_time - start_time
            
            # åˆ†æç»“æœ
            successful_connections = 0
            failed_connections = 0
            errors = []
            
            for result in results:
                if isinstance(result, dict):
                    if result.get('success', False):
                        successful_connections += 1
                    else:
                        failed_connections += 1
                        errors.append(result.get('error', 'Unknown error'))
                else:
                    failed_connections += 1
                    errors.append(str(result))
            
            success_rate = successful_connections / concurrent_count
            avg_time_per_connection = total_time / concurrent_count
            
            print(f"âœ… å¹¶å‘è¿æ¥æµ‹è¯•ç»“æœ ({concurrent_count} è¿æ¥):")
            print(f"   æˆåŠŸè¿æ¥: {successful_connections}")
            print(f"   å¤±è´¥è¿æ¥: {failed_connections}")
            print(f"   æˆåŠŸç‡: {success_rate:.1%}")
            print(f"   æ€»è€—æ—¶: {total_time:.3f}ç§’")
            print(f"   å¹³å‡è¿æ¥æ—¶é—´: {avg_time_per_connection:.3f}ç§’")
            
            if errors:
                unique_errors = list(set(errors[:5]))  # æ˜¾ç¤ºå‰5ç§ä¸åŒé”™è¯¯
                print(f"   é”™è¯¯æ ·ä¾‹: {unique_errors}")
            
            # å¹¶å‘æ€§èƒ½æ–­è¨€
            assert success_rate >= 0.8, f"å¹¶å‘è¿æ¥æˆåŠŸç‡è¿‡ä½: {success_rate:.1%}"
            assert avg_time_per_connection < 1.0, f"å¹³å‡è¿æ¥æ—¶é—´è¿‡é•¿: {avg_time_per_connection:.3f}s"

    @pytest.mark.performance
    @pytest.mark.asyncio
    async def test_concurrent_reads(self, db_pool: asyncpg.Pool):
        """æµ‹è¯•å¹¶å‘è¯»æ“ä½œ"""
        # æ£€æŸ¥usersè¡¨æ˜¯å¦å­˜åœ¨
        async with db_pool.acquire() as connection:
            table_exists = await connection.fetchval(
                "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'users')"
            )
        
        if not table_exists:
            pytest.skip("usersè¡¨ä¸å­˜åœ¨")

        async def concurrent_read_worker(worker_id: int, iterations: int):
            """å¹¶å‘è¯»å·¥ä½œè¿›ç¨‹"""
            successful_reads = 0
            read_times = []
            
            try:
                async with db_pool.acquire() as connection:
                    for i in range(iterations):
                        start_time = time.time()
                        
                        # æ‰§è¡Œä¸åŒç±»å‹çš„è¯»æŸ¥è¯¢
                        query_type = i % 4
                        if query_type == 0:
                            result = await connection.fetchval("SELECT COUNT(*) FROM users")
                        elif query_type == 1:
                            result = await connection.fetch("SELECT * FROM users LIMIT 5")
                        elif query_type == 2:
                            result = await connection.fetchval("SELECT MAX(created_at) FROM users")
                        else:
                            result = await connection.fetch("SELECT is_active, COUNT(*) FROM users GROUP BY is_active")
                        
                        end_time = time.time()
                        read_times.append(end_time - start_time)
                        
                        if result is not None:
                            successful_reads += 1
                        
                        # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
                        await asyncio.sleep(0.01)
                
                return {
                    'worker_id': worker_id,
                    'successful_reads': successful_reads,
                    'total_iterations': iterations,
                    'avg_read_time': sum(read_times) / len(read_times) if read_times else 0,
                    'max_read_time': max(read_times) if read_times else 0
                }
                
            except Exception as e:
                return {
                    'worker_id': worker_id,
                    'error': str(e),
                    'successful_reads': successful_reads
                }

        # å¯åŠ¨å¤šä¸ªå¹¶å‘è¯»å·¥ä½œè¿›ç¨‹
        worker_count = 8
        iterations_per_worker = 20
        
        print(f"ğŸ”„ å¯åŠ¨ {worker_count} ä¸ªå¹¶å‘è¯»å·¥ä½œè¿›ç¨‹ï¼Œæ¯ä¸ªæ‰§è¡Œ {iterations_per_worker} æ¬¡è¯»æ“ä½œ")
        
        start_time = time.time()
        
        tasks = []
        for worker_id in range(worker_count):
            task = asyncio.create_task(concurrent_read_worker(worker_id, iterations_per_worker))
            tasks.append(task)
        
        results = await asyncio.gather(*tasks)
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # åˆ†æç»“æœ
        total_successful_reads = sum(r.get('successful_reads', 0) for r in results)
        total_expected_reads = worker_count * iterations_per_worker
        success_rate = total_successful_reads / total_expected_reads
        
        avg_read_times = [r.get('avg_read_time', 0) for r in results if 'avg_read_time' in r]
        overall_avg_read_time = sum(avg_read_times) / len(avg_read_times) if avg_read_times else 0
        
        throughput = total_successful_reads / total_time
        
        print(f"âœ… å¹¶å‘è¯»æ“ä½œæµ‹è¯•ç»“æœ:")
        print(f"   æ€»è¯»æ“ä½œ: {total_successful_reads}/{total_expected_reads}")
        print(f"   æˆåŠŸç‡: {success_rate:.1%}")
        print(f"   æ€»è€—æ—¶: {total_time:.3f}ç§’")
        print(f"   å¹³å‡è¯»æ“ä½œæ—¶é—´: {overall_avg_read_time:.6f}ç§’")
        print(f"   ååé‡: {throughput:.1f} è¯»/ç§’")
        
        # æ€§èƒ½æ–­è¨€
        assert success_rate >= 0.95, f"å¹¶å‘è¯»æˆåŠŸç‡è¿‡ä½: {success_rate:.1%}"
        assert throughput > 50, f"è¯»æ“ä½œååé‡è¿‡ä½: {throughput:.1f} è¯»/ç§’"

    @pytest.mark.performance
    @pytest.mark.asyncio
    async def test_concurrent_writes(self, db_pool: asyncpg.Pool):
        """æµ‹è¯•å¹¶å‘å†™æ“ä½œ"""
        # æ£€æŸ¥usersè¡¨æ˜¯å¦å­˜åœ¨
        async with db_pool.acquire() as connection:
            table_exists = await connection.fetchval(
                "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'users')"
            )
        
        if not table_exists:
            pytest.skip("usersè¡¨ä¸å­˜åœ¨")

        async def concurrent_write_worker(worker_id: int, iterations: int):
            """å¹¶å‘å†™å·¥ä½œè¿›ç¨‹"""
            successful_writes = 0
            write_times = []
            created_records = []
            
            try:
                async with db_pool.acquire() as connection:
                    async with connection.transaction():
                        for i in range(iterations):
                            start_time = time.time()
                            
                            try:
                                # åˆ›å»ºå”¯ä¸€çš„ç”¨æˆ·
                                email = f"concurrent_write_{worker_id}_{i}@example.com"
                                username = f"concurrent_user_{worker_id}_{i}"
                                
                                user_id = await connection.fetchval(
                                    """
                                    INSERT INTO users (email, username, password_hash, is_active)
                                    VALUES ($1, $2, $3, $4)
                                    RETURNING id
                                    """,
                                    email, username, 'concurrent_hash', True
                                )
                                
                                if user_id:
                                    created_records.append(user_id)
                                    successful_writes += 1
                                
                                end_time = time.time()
                                write_times.append(end_time - start_time)
                                
                            except Exception as write_error:
                                # è®°å½•å†™å…¥é”™è¯¯ä½†ç»§ç»­
                                end_time = time.time()
                                write_times.append(end_time - start_time)
                                print(f"Worker {worker_id} å†™å…¥é”™è¯¯: {write_error}")
                            
                            # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
                            await asyncio.sleep(0.01)
                
                return {
                    'worker_id': worker_id,
                    'successful_writes': successful_writes,
                    'total_iterations': iterations,
                    'created_records': len(created_records),
                    'avg_write_time': sum(write_times) / len(write_times) if write_times else 0,
                    'max_write_time': max(write_times) if write_times else 0
                }
                
            except Exception as e:
                return {
                    'worker_id': worker_id,
                    'error': str(e),
                    'successful_writes': successful_writes
                }

        # å¯åŠ¨å¤šä¸ªå¹¶å‘å†™å·¥ä½œè¿›ç¨‹
        worker_count = 4  # å‡å°‘å†™å¹¶å‘ä»¥é¿å…é”ç«äº‰
        iterations_per_worker = 10
        
        print(f"ğŸ”„ å¯åŠ¨ {worker_count} ä¸ªå¹¶å‘å†™å·¥ä½œè¿›ç¨‹ï¼Œæ¯ä¸ªæ‰§è¡Œ {iterations_per_worker} æ¬¡å†™æ“ä½œ")
        
        start_time = time.time()
        
        tasks = []
        for worker_id in range(worker_count):
            task = asyncio.create_task(concurrent_write_worker(worker_id, iterations_per_worker))
            tasks.append(task)
        
        results = await asyncio.gather(*tasks)
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # åˆ†æç»“æœ
        total_successful_writes = sum(r.get('successful_writes', 0) for r in results)
        total_expected_writes = worker_count * iterations_per_worker
        success_rate = total_successful_writes / total_expected_writes
        
        avg_write_times = [r.get('avg_write_time', 0) for r in results if 'avg_write_time' in r]
        overall_avg_write_time = sum(avg_write_times) / len(avg_write_times) if avg_write_times else 0
        
        throughput = total_successful_writes / total_time
        
        print(f"âœ… å¹¶å‘å†™æ“ä½œæµ‹è¯•ç»“æœ:")
        print(f"   æ€»å†™æ“ä½œ: {total_successful_writes}/{total_expected_writes}")
        print(f"   æˆåŠŸç‡: {success_rate:.1%}")
        print(f"   æ€»è€—æ—¶: {total_time:.3f}ç§’")
        print(f"   å¹³å‡å†™æ“ä½œæ—¶é—´: {overall_avg_write_time:.6f}ç§’")
        print(f"   ååé‡: {throughput:.1f} å†™/ç§’")
        
        # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        errors = [r.get('error') for r in results if 'error' in r]
        if errors:
            print(f"   é‡åˆ°é”™è¯¯: {len(errors)} ä¸ªå·¥ä½œè¿›ç¨‹")
        
        # æ€§èƒ½æ–­è¨€ï¼ˆå†™æ“ä½œå®¹è®¸è¾ƒä½çš„æˆåŠŸç‡ï¼‰
        assert success_rate >= 0.7, f"å¹¶å‘å†™æˆåŠŸç‡è¿‡ä½: {success_rate:.1%}"

    @pytest.mark.performance
    @pytest.mark.asyncio
    async def test_transaction_isolation(self, db_pool: asyncpg.Pool):
        """æµ‹è¯•äº‹åŠ¡éš”ç¦»çº§åˆ«"""
        # æ£€æŸ¥usersè¡¨æ˜¯å¦å­˜åœ¨
        async with db_pool.acquire() as connection:
            table_exists = await connection.fetchval(
                "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'users')"
            )
        
        if not table_exists:
            pytest.skip("usersè¡¨ä¸å­˜åœ¨")

        async def transaction_worker_a():
            """äº‹åŠ¡A - æ›´æ–°ç”¨æˆ·çŠ¶æ€"""
            async with db_pool.acquire() as connection:
                async with connection.transaction():
                    # åˆ›å»ºæµ‹è¯•ç”¨æˆ·
                    user_id = await connection.fetchval(
                        """
                        INSERT INTO users (email, username, password_hash, is_active)
                        VALUES ($1, $2, $3, $4)
                        RETURNING id
                        """,
                        'isolation_test_a@example.com', 'isolation_user_a', 'hash', True
                    )
                    
                    # æ¨¡æ‹Ÿé•¿æ—¶é—´å¤„ç†
                    await asyncio.sleep(0.5)
                    
                    # æ›´æ–°ç”¨æˆ·çŠ¶æ€
                    await connection.execute(
                        "UPDATE users SET is_active = false WHERE id = $1",
                        user_id
                    )
                    
                    # å†æ¬¡ç¡çœ æ¨¡æ‹Ÿæ›´å¤šå¤„ç†
                    await asyncio.sleep(0.3)
                    
                    return user_id

        async def transaction_worker_b():
            """äº‹åŠ¡B - è¯»å–ç”¨æˆ·çŠ¶æ€"""
            async with db_pool.acquire() as connection:
                # ç­‰å¾…äº‹åŠ¡Aå¼€å§‹
                await asyncio.sleep(0.1)
                
                # å°è¯•è¯»å–æ•°æ®ï¼ˆåº”è¯¥åœ¨äº‹åŠ¡Aæäº¤å‰åçœ‹åˆ°ä¸åŒç»“æœï¼‰
                before_results = []
                after_results = []
                
                # äº‹åŠ¡Aæ‰§è¡ŒæœŸé—´çš„è¯»å–
                for _ in range(3):
                    count_active = await connection.fetchval(
                        "SELECT COUNT(*) FROM users WHERE email LIKE 'isolation_test_%' AND is_active = true"
                    )
                    before_results.append(count_active)
                    await asyncio.sleep(0.2)
                
                # ç­‰å¾…äº‹åŠ¡Aå®Œæˆ
                await asyncio.sleep(1.0)
                
                # äº‹åŠ¡Aå®Œæˆåçš„è¯»å–
                count_active_after = await connection.fetchval(
                    "SELECT COUNT(*) FROM users WHERE email LIKE 'isolation_test_%' AND is_active = true"
                )
                after_results.append(count_active_after)
                
                return {
                    'before_commit': before_results,
                    'after_commit': after_results
                }

        # å¯åŠ¨ä¸¤ä¸ªå¹¶å‘äº‹åŠ¡
        print("ğŸ”„ æµ‹è¯•äº‹åŠ¡éš”ç¦»çº§åˆ«")
        
        start_time = time.time()
        
        task_a = asyncio.create_task(transaction_worker_a())
        task_b = asyncio.create_task(transaction_worker_b())
        
        results = await asyncio.gather(task_a, task_b)
        
        end_time = time.time()
        total_time = end_time - start_time
        
        user_id_a = results[0]
        read_results = results[1]
        
        print(f"âœ… äº‹åŠ¡éš”ç¦»æµ‹è¯•ç»“æœ:")
        print(f"   æ‰§è¡Œæ—¶é—´: {total_time:.3f}ç§’")
        print(f"   äº‹åŠ¡Aåˆ›å»ºç”¨æˆ·ID: {user_id_a}")
        print(f"   äº‹åŠ¡Bæäº¤å‰è¯»å–: {read_results['before_commit']}")
        print(f"   äº‹åŠ¡Bæäº¤åè¯»å–: {read_results['after_commit']}")
        
        # æ¸…ç†æµ‹è¯•æ•°æ®
        async with db_pool.acquire() as connection:
            await connection.execute(
                "DELETE FROM users WHERE email LIKE 'isolation_test_%'"
            )

    @pytest.mark.performance
    @pytest.mark.asyncio
    async def test_deadlock_detection(self, db_pool: asyncpg.Pool):
        """æµ‹è¯•æ­»é”æ£€æµ‹å’Œå¤„ç†"""
        # æ£€æŸ¥usersè¡¨æ˜¯å¦å­˜åœ¨
        async with db_pool.acquire() as connection:
            table_exists = await connection.fetchval(
                "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'users')"
            )
        
        if not table_exists:
            pytest.skip("usersè¡¨ä¸å­˜åœ¨")

        # é¦–å…ˆåˆ›å»ºä¸¤ä¸ªæµ‹è¯•ç”¨æˆ·
        async with db_pool.acquire() as connection:
            user1_id = await connection.fetchval(
                """
                INSERT INTO users (email, username, password_hash, is_active)
                VALUES ($1, $2, $3, $4)
                RETURNING id
                """,
                'deadlock_test_1@example.com', 'deadlock_user_1', 'hash', True
            )
            
            user2_id = await connection.fetchval(
                """
                INSERT INTO users (email, username, password_hash, is_active)
                VALUES ($1, $2, $3, $4)
                RETURNING id
                """,
                'deadlock_test_2@example.com', 'deadlock_user_2', 'hash', True
            )

        async def deadlock_worker_1():
            """å¯èƒ½å¯¼è‡´æ­»é”çš„äº‹åŠ¡1"""
            try:
                async with db_pool.acquire() as connection:
                    async with connection.transaction():
                        # é¦–å…ˆé”å®šç”¨æˆ·1
                        await connection.execute(
                            "UPDATE users SET is_active = false WHERE id = $1",
                            user1_id
                        )
                        
                        # ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œè®©äº‹åŠ¡2ä¹Ÿå¼€å§‹
                        await asyncio.sleep(0.5)
                        
                        # å°è¯•é”å®šç”¨æˆ·2ï¼ˆå¯èƒ½å¯¼è‡´æ­»é”ï¼‰
                        await connection.execute(
                            "UPDATE users SET is_active = false WHERE id = $1",
                            user2_id
                        )
                        
                        return {'success': True, 'transaction': 1}
                        
            except Exception as e:
                error_msg = str(e)
                is_deadlock = 'deadlock detected' in error_msg.lower()
                return {
                    'success': False,
                    'transaction': 1,
                    'error': error_msg,
                    'is_deadlock': is_deadlock
                }

        async def deadlock_worker_2():
            """å¯èƒ½å¯¼è‡´æ­»é”çš„äº‹åŠ¡2"""
            try:
                # ç¨å¾®å»¶è¿Ÿå¯åŠ¨ï¼Œä½†ä¸è¦å¤ªé•¿
                await asyncio.sleep(0.1)
                
                async with db_pool.acquire() as connection:
                    async with connection.transaction():
                        # é¦–å…ˆé”å®šç”¨æˆ·2
                        await connection.execute(
                            "UPDATE users SET is_active = true WHERE id = $1",
                            user2_id
                        )
                        
                        # ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œç¡®ä¿äº‹åŠ¡1ä¹Ÿåœ¨è¿›è¡Œ
                        await asyncio.sleep(0.5)
                        
                        # å°è¯•é”å®šç”¨æˆ·1ï¼ˆå¯èƒ½å¯¼è‡´æ­»é”ï¼‰
                        await connection.execute(
                            "UPDATE users SET is_active = true WHERE id = $1",
                            user1_id
                        )
                        
                        return {'success': True, 'transaction': 2}
                        
            except Exception as e:
                error_msg = str(e)
                is_deadlock = 'deadlock detected' in error_msg.lower()
                return {
                    'success': False,
                    'transaction': 2,
                    'error': error_msg,
                    'is_deadlock': is_deadlock
                }

        print("ğŸ”„ æµ‹è¯•æ­»é”æ£€æµ‹å’Œå¤„ç†")
        
        start_time = time.time()
        
        # å¯åŠ¨å¯èƒ½å¯¼è‡´æ­»é”çš„ä¸¤ä¸ªäº‹åŠ¡
        task1 = asyncio.create_task(deadlock_worker_1())
        task2 = asyncio.create_task(deadlock_worker_2())
        
        results = await asyncio.gather(task1, task2, return_exceptions=True)
        
        end_time = time.time()
        total_time = end_time - start_time
        
        print(f"âœ… æ­»é”æ£€æµ‹æµ‹è¯•ç»“æœ:")
        print(f"   æ‰§è¡Œæ—¶é—´: {total_time:.3f}ç§’")
        
        deadlock_detected = False
        successful_transactions = 0
        
        for i, result in enumerate(results):
            if isinstance(result, dict):
                if result.get('success', False):
                    successful_transactions += 1
                    print(f"   äº‹åŠ¡{result['transaction']}: æˆåŠŸå®Œæˆ")
                else:
                    if result.get('is_deadlock', False):
                        deadlock_detected = True
                        print(f"   äº‹åŠ¡{result['transaction']}: æ£€æµ‹åˆ°æ­»é”")
                    else:
                        print(f"   äº‹åŠ¡{result['transaction']}: å…¶ä»–é”™è¯¯ - {result.get('error', 'Unknown')[:100]}")
            else:
                print(f"   äº‹åŠ¡{i+1}: å¼‚å¸¸ - {str(result)[:100]}")
        
        print(f"   æˆåŠŸäº‹åŠ¡: {successful_transactions}/2")
        print(f"   æ­»é”æ£€æµ‹: {'æ˜¯' if deadlock_detected else 'å¦'}")
        
        # æ¸…ç†æµ‹è¯•æ•°æ®
        async with db_pool.acquire() as connection:
            await connection.execute(
                "DELETE FROM users WHERE email LIKE 'deadlock_test_%'"
            )
        
        # æ–­è¨€ï¼šåº”è¯¥è‡³å°‘æœ‰ä¸€ä¸ªäº‹åŠ¡æˆåŠŸï¼Œæˆ–è€…æ£€æµ‹åˆ°æ­»é”
        assert successful_transactions > 0 or deadlock_detected, \
            "åº”è¯¥æœ‰æˆåŠŸçš„äº‹åŠ¡æˆ–è€…æ£€æµ‹åˆ°æ­»é”"

    @pytest.mark.performance
    @pytest.mark.slow
    @pytest.mark.asyncio
    async def test_long_running_transactions(self, db_pool: asyncpg.Pool):
        """æµ‹è¯•é•¿æ—¶é—´è¿è¡Œçš„äº‹åŠ¡"""
        # æ£€æŸ¥usersè¡¨æ˜¯å¦å­˜åœ¨
        async with db_pool.acquire() as connection:
            table_exists = await connection.fetchval(
                "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'users')"
            )
        
        if not table_exists:
            pytest.skip("usersè¡¨ä¸å­˜åœ¨")

        async def long_running_transaction(transaction_id: int, duration: float):
            """é•¿æ—¶é—´è¿è¡Œçš„äº‹åŠ¡"""
            try:
                async with db_pool.acquire() as connection:
                    async with connection.transaction():
                        # åˆ›å»ºç”¨æˆ·
                        user_id = await connection.fetchval(
                            """
                            INSERT INTO users (email, username, password_hash, is_active)
                            VALUES ($1, $2, $3, $4)
                            RETURNING id
                            """,
                            f'long_tx_{transaction_id}@example.com',
                            f'long_tx_user_{transaction_id}',
                            'long_hash', True
                        )
                        
                        # æ¨¡æ‹Ÿé•¿æ—¶é—´å¤„ç†
                        await asyncio.sleep(duration)
                        
                        # æ›´æ–°ç”¨æˆ·
                        await connection.execute(
                            "UPDATE users SET is_active = false WHERE id = $1",
                            user_id
                        )
                        
                        # å†æ¬¡å¤„ç†
                        await asyncio.sleep(duration / 2)
                        
                        return {
                            'transaction_id': transaction_id,
                            'success': True,
                            'user_id': user_id,
                            'duration': duration
                        }
                        
            except Exception as e:
                return {
                    'transaction_id': transaction_id,
                    'success': False,
                    'error': str(e),
                    'duration': duration
                }

        async def concurrent_short_operations():
            """å¹¶å‘çš„çŸ­æ“ä½œ"""
            operations_completed = 0
            
            for i in range(20):
                try:
                    async with db_pool.acquire() as connection:
                        # å¿«é€ŸæŸ¥è¯¢æ“ä½œ
                        count = await connection.fetchval("SELECT COUNT(*) FROM users")
                        if isinstance(count, int):
                            operations_completed += 1
                        
                        await asyncio.sleep(0.05)  # 50msé—´éš”
                        
                except Exception as e:
                    print(f"çŸ­æ“ä½œ {i} å¤±è´¥: {e}")
            
            return operations_completed

        print("ğŸ”„ æµ‹è¯•é•¿æ—¶é—´è¿è¡Œäº‹åŠ¡çš„å½±å“")
        
        # å¯åŠ¨é•¿äº‹åŠ¡å’ŒçŸ­æ“ä½œ
        start_time = time.time()
        
        # å¯åŠ¨2ä¸ªé•¿äº‹åŠ¡
        long_tx_tasks = [
            asyncio.create_task(long_running_transaction(1, 2.0)),
            asyncio.create_task(long_running_transaction(2, 1.5))
        ]
        
        # å¯åŠ¨çŸ­æ“ä½œ
        short_ops_task = asyncio.create_task(concurrent_short_operations())
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        all_tasks = long_tx_tasks + [short_ops_task]
        results = await asyncio.gather(*all_tasks)
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # åˆ†æç»“æœ
        long_tx_results = results[:-1]
        short_ops_completed = results[-1]
        
        successful_long_tx = sum(1 for r in long_tx_results if r.get('success', False))
        
        print(f"âœ… é•¿äº‹åŠ¡æµ‹è¯•ç»“æœ:")
        print(f"   æ€»æ‰§è¡Œæ—¶é—´: {total_time:.3f}ç§’")
        print(f"   é•¿äº‹åŠ¡æˆåŠŸ: {successful_long_tx}/{len(long_tx_results)}")
        print(f"   çŸ­æ“ä½œå®Œæˆ: {short_ops_completed}/20")
        
        for result in long_tx_results:
            if result.get('success', False):
                print(f"   é•¿äº‹åŠ¡{result['transaction_id']}: æˆåŠŸ ({result['duration']}s)")
            else:
                print(f"   é•¿äº‹åŠ¡{result['transaction_id']}: å¤±è´¥ - {result.get('error', 'Unknown')[:50]}")
        
        # æ¸…ç†æµ‹è¯•æ•°æ®
        async with db_pool.acquire() as connection:
            await connection.execute("DELETE FROM users WHERE email LIKE 'long_tx_%'")
        
        # æ–­è¨€ï¼šé•¿äº‹åŠ¡ä¸åº”è¯¥æ˜¾è‘—å½±å“çŸ­æ“ä½œ
        short_ops_success_rate = short_ops_completed / 20
        assert short_ops_success_rate >= 0.8, \
            f"é•¿äº‹åŠ¡ä¸¥é‡å½±å“äº†çŸ­æ“ä½œ: æˆåŠŸç‡ä»… {short_ops_success_rate:.1%}"

    @pytest.mark.performance
    @pytest.mark.asyncio
    async def test_connection_pool_stress(self, db_config: Dict[str, Any]):
        """æµ‹è¯•è¿æ¥æ± å‹åŠ›"""
        # åˆ›å»ºå°çš„è¿æ¥æ± è¿›è¡Œå‹åŠ›æµ‹è¯•
        connection_string = f"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['db_name']}"
        
        pool = await asyncpg.create_pool(
            connection_string,
            min_size=2,
            max_size=5,  # å°è¿æ¥æ± 
            command_timeout=30
        )
        
        async def pool_worker(worker_id: int, operations: int):
            """è¿æ¥æ± å·¥ä½œè¿›ç¨‹"""
            successful_operations = 0
            wait_times = []
            
            for i in range(operations):
                start_wait = time.time()
                
                try:
                    async with pool.acquire() as connection:
                        end_wait = time.time()
                        wait_times.append(end_wait - start_wait)
                        
                        # æ‰§è¡Œä¸€äº›æ•°æ®åº“æ“ä½œ
                        await connection.fetchval("SELECT $1", f"worker_{worker_id}_op_{i}")
                        
                        # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
                        await asyncio.sleep(random.uniform(0.1, 0.3))
                        
                        successful_operations += 1
                        
                except Exception as e:
                    print(f"Worker {worker_id} æ“ä½œ {i} å¤±è´¥: {e}")
            
            return {
                'worker_id': worker_id,
                'successful_operations': successful_operations,
                'total_operations': operations,
                'avg_wait_time': sum(wait_times) / len(wait_times) if wait_times else 0,
                'max_wait_time': max(wait_times) if wait_times else 0
            }
        
        try:
            print("ğŸ”„ æµ‹è¯•è¿æ¥æ± å‹åŠ› (æœ€å¤§5ä¸ªè¿æ¥)")
            
            # å¯åŠ¨10ä¸ªå·¥ä½œè¿›ç¨‹ç«äº‰5ä¸ªè¿æ¥
            worker_count = 10
            operations_per_worker = 8
            
            start_time = time.time()
            
            tasks = []
            for worker_id in range(worker_count):
                task = asyncio.create_task(pool_worker(worker_id, operations_per_worker))
                tasks.append(task)
            
            results = await asyncio.gather(*tasks)
            
            end_time = time.time()
            total_time = end_time - start_time
            
            # åˆ†æç»“æœ
            total_successful = sum(r['successful_operations'] for r in results)
            total_expected = worker_count * operations_per_worker
            success_rate = total_successful / total_expected
            
            avg_wait_times = [r['avg_wait_time'] for r in results if r['avg_wait_time'] > 0]
            overall_avg_wait = sum(avg_wait_times) / len(avg_wait_times) if avg_wait_times else 0
            
            max_wait_time = max((r['max_wait_time'] for r in results), default=0)
            
            print(f"âœ… è¿æ¥æ± å‹åŠ›æµ‹è¯•ç»“æœ:")
            print(f"   å·¥ä½œè¿›ç¨‹: {worker_count}")
            print(f"   è¿æ¥æ± å¤§å°: 2-5")
            print(f"   æ€»æ“ä½œ: {total_successful}/{total_expected}")
            print(f"   æˆåŠŸç‡: {success_rate:.1%}")
            print(f"   æ€»è€—æ—¶: {total_time:.3f}ç§’")
            print(f"   å¹³å‡ç­‰å¾…æ—¶é—´: {overall_avg_wait:.3f}ç§’")
            print(f"   æœ€é•¿ç­‰å¾…æ—¶é—´: {max_wait_time:.3f}ç§’")
            
            # æ€§èƒ½æ–­è¨€
            assert success_rate >= 0.9, f"è¿æ¥æ± å‹åŠ›æµ‹è¯•æˆåŠŸç‡è¿‡ä½: {success_rate:.1%}"
            assert overall_avg_wait < 1.0, f"è¿æ¥æ± ç­‰å¾…æ—¶é—´è¿‡é•¿: {overall_avg_wait:.3f}s"
            
        finally:
            await pool.close()

    @pytest.mark.performance
    @pytest.mark.asyncio
    async def test_query_timeout_handling(self, db_pool: asyncpg.Pool):
        """æµ‹è¯•æŸ¥è¯¢è¶…æ—¶å¤„ç†"""
        print("ğŸ”„ æµ‹è¯•æŸ¥è¯¢è¶…æ—¶å¤„ç†")
        
        async def timeout_test_query(timeout_seconds: float):
            """æ‰§è¡Œå¯èƒ½è¶…æ—¶çš„æŸ¥è¯¢"""
            try:
                async with db_pool.acquire() as connection:
                    # è®¾ç½®æŸ¥è¯¢è¶…æ—¶
                    start_time = time.time()
                    
                    result = await asyncio.wait_for(
                        connection.fetchval("SELECT pg_sleep($1), 'completed'", timeout_seconds),
                        timeout=timeout_seconds + 0.5
                    )
                    
                    end_time = time.time()
                    actual_time = end_time - start_time
                    
                    return {
                        'success': True,
                        'expected_time': timeout_seconds,
                        'actual_time': actual_time,
                        'result': result
                    }
                    
            except asyncio.TimeoutError:
                end_time = time.time()
                actual_time = end_time - start_time
                return {
                    'success': False,
                    'timeout': True,
                    'expected_time': timeout_seconds,
                    'actual_time': actual_time
                }
            except Exception as e:
                return {
                    'success': False,
                    'timeout': False,
                    'error': str(e),
                    'expected_time': timeout_seconds
                }

        # æµ‹è¯•ä¸åŒçš„è¶…æ—¶åœºæ™¯
        timeout_tests = [
            0.1,  # 100ms - åº”è¯¥æˆåŠŸ
            0.5,  # 500ms - åº”è¯¥æˆåŠŸ
            1.0,  # 1s - åº”è¯¥æˆåŠŸä½†è¾ƒæ…¢
            # 2.0   # 2s - å¯èƒ½è¶…æ—¶ï¼ˆå–å†³äºæœåŠ¡å™¨æ€§èƒ½ï¼‰
        ]
        
        results = []
        for timeout in timeout_tests:
            print(f"   æµ‹è¯• {timeout}ç§’ è¶…æ—¶...")
            result = await timeout_test_query(timeout)
            results.append(result)
            
            if result['success']:
                print(f"   âœ… {timeout}ç§’æŸ¥è¯¢æˆåŠŸï¼Œå®é™…è€—æ—¶: {result['actual_time']:.3f}ç§’")
            elif result.get('timeout', False):
                print(f"   â±ï¸  {timeout}ç§’æŸ¥è¯¢è¶…æ—¶ï¼Œå®é™…è€—æ—¶: {result['actual_time']:.3f}ç§’")
            else:
                print(f"   âŒ {timeout}ç§’æŸ¥è¯¢å¤±è´¥: {result.get('error', 'Unknown')}")
        
        # éªŒè¯è¶…æ—¶æœºåˆ¶å·¥ä½œæ­£å¸¸
        successful_queries = sum(1 for r in results if r['success'])
        print(f"âœ… æŸ¥è¯¢è¶…æ—¶æµ‹è¯•å®Œæˆ: {successful_queries}/{len(results)} ä¸ªæŸ¥è¯¢æˆåŠŸ")
        
        # è‡³å°‘çŸ­æ—¶é—´çš„æŸ¥è¯¢åº”è¯¥æˆåŠŸ
        short_queries = [r for r in results if r['expected_time'] <= 0.5]
        short_successful = sum(1 for r in short_queries if r['success'])
        
        if short_queries:
            assert short_successful > 0, "çŸ­æ—¶é—´æŸ¥è¯¢åº”è¯¥è‡³å°‘æœ‰ä¸€ä¸ªæˆåŠŸ"